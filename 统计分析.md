## 描述性统计

样本均值、样本标准差 => 总体平均水平、总体标准差

### 相关性

#### 适用场景

衡量两个线性相关变量的相关性。

#### 实现细节

**Pearson相关系数**

$$
\rho_{XY} = \frac{Cov(X, Y)}{\sigma_X \sigma_Y} = \frac{\sum_{i=1}^n \frac{X_i-E(X)}{\sigma_X} \frac{Y_i-E(Y)}{\sigma_Y} }{n}
$$

可以证明$\rho_{XY} < 1$，且当$Y=aX+b$，有
$$
\rho_{XY} = \left\{ 
    \begin{aligned}
        1 & , a>0 \\
        -1 & , a < 0 \
    \end{aligned}
\right.
$$

计算样本的Pearson相关系数时，使用无偏标准差

$$
r_{XY} = \frac{Cov(X, Y)}{S_X S_Y} \\ ~ \\
where ~ S_X = \sqrt{\frac{\sum (X_i - \bar{X})}{n-1}} \\~\\
and ~ S_Y = \sqrt{\frac{\sum (Y_i - \bar{Y})}{n-1}}
$$

绘制散点图以可视化两个数据间的相关性

可对Pearson相关系数进行**假设检验**

- 提出原假设$H_0$和备择假设$H_1$
- 在原假设成立的条件下，利用要检验的统计量构造检验统计量（符合某一分布的统计量）
  - 标准正态分布：**大样本**（容量大于30）、**总体的方差已知**的平均值差异检验 
    若检验某个样本平均数与整体平均数是否明显差异：
    $$
        Z=\frac{\bar X - \mu_0}{\frac{S}{\sqrt{n}}}
    $$
    若检验两组样本平均数的差异：
    $$
        Z = \frac{\bar X_1 - \bar X_2}{\sqrt{\frac{S_1}{n_1} + \frac{S_2}{n_2}}}
    $$
  - $t$分布：**小样本**（容量小于30）、**总体标准差已知**的平均值差异检验
    自由度$v=n-1$
    若检验某个样本平均数与整体平均数是否明显差异：
    $$
        T = \frac{\bar X - \mu_0}{\frac{S}{\sqrt{n-1}}}
    $$
    若检验两组样本平均数的差异：
    $$
        T = \frac{\bar X_1 - \bar X_2}{\sqrt{\frac{\sum x_1^2 + x_2^2}{n_1 + n_2 - 2}}\times \frac{n_1 + n_2}{n_1 \times n_2}}
    $$
  - $\chi^2$分布：分类变量的独立性检验，或分类变量的比较检验，核心是比较理论频数和实际频数
    在各种条件下，可对$\chi^2$分布进行各种改进，详见[Furthur Reading](https://zhuanlan.zhihu.com/p/140043959)
    对共$N$个变量的$R \times C$联立表，理论频数
    $$
        T_ij = \frac{\sum_{c=i}^C A_{ic}\sum_{r=i}^R A_{rj}}{N}
    $$
    卡方统计量
    $$
        \chi^2 = \sum_i^R \sum_j^C \frac{(A_{ij} - T_{ij})^2}{T_{ij}} \sim \chi^2((R-1)(C-1))
    $$
    进行不用计算频数的化简：
    $$
        \chi^2 = N\left(\sum_i^R \sum_j^C \frac{A_{ij}^2}{\sum_{c=i}^C A_{ic}\sum_{r=1}^R A_{rj}} -1 \right) \sim \chi^2((R-1)(C-1))
    $$
  - F分布：两个正态随机变量的总体方差是否相等（方差齐性）
    $$
        F = \frac{s_1^2}{s_2^2} \sim F(n_1-1, n_2-1)
    $$
- 一定条件下，可构造$t=r\sqrt{\frac{n-2}{1-r^2}}$，$t$服从自由度为$n-2$的$t$分布
- 画出选择分布的概率密度函数，给定置信水平，得到接受域和拒绝域
- 计算检验统计量落在接受域还是拒绝域，若在拒绝域，可拒绝原假设。
    ***值得注意的是，如果检验统计量落在接受域，不能得出接受原假设的结论，只能说不能拒绝原假设。***
    > 就比如我说实际上没有白色的乌鸦，我无法证明，但fail to reject（无法拒绝），因为我还暂时找不出白色乌鸦，但我不能证明不存在。 ~ Mr. Li
- 更好的方法是用$p$值（概率）判断。将检验统计量带入tcdf（累计分布函数），得到p值，有
    $$
    \begin{aligned}
        p < 0.01, & 在99\%置信水平上可拒绝原假设 \\
        p < 0.05, & 在95\%置信水平上可拒绝原假设 \\
        p < 0.10, & 在90\%置信水平上可拒绝原假设
    \end{aligned}
    $$
    etc.
    对Pearson相关系数的检验中，若拒绝原假设，则可认为Pearson相关系数显著异于0

假设检验用到了$t$检验，基于的假设是数据呈正态分布。为了检验数据是否符合正态分布，可使用**Jarque-Bera Test**（雅克-贝拉检验，JB检验）

随机变量的偏度（Skewness）可用于描述变量对均值的偏向（左偏或右偏）：
$$
S = \frac{1}{n} \sum_i^n \left[ \left( \frac{X_i - \mu}{\sigma} \right)^3  \right]
$$

随机变量的峰度（Kurtosis）可用于描述随机变量概率分布的陡峭程度：
$$
K = \frac{1}{n} \sum_i^n \left[ \left( \frac{X_i - \mu}{\sigma} \right)^4  \right]  
$$

基于此，可以构造JB统计量：
$$
JB = \frac{n}{6}\left[ S^2 + \frac{(K-3)^2}{4} \right]
$$

如果${X_i}$是正态分布，且样本足够大，有
$$
JB \sim \chi^2(2)
$$

可对其做假设检验，原假设$H_0$为该随机变量符合正态分布，细节略。

数据量较小时（3~50），可以适用Shapiro-Wilk检验。详见[知乎](https://zhuanlan.zhihu.com/p/61590292)或[CSDN](https://blog.csdn.net/zzminer/article/details/8858469)

数据量足够大时，可用Q-Q图。将待检测的数据与正态分布数据相同分位数的值分别作为横纵坐标作图。若待检测数据符合正态分布，图像应该与$y=x$重合。

**Spearman相关系数**

一组数据的**等级**是指，将数据从小到大排列之后，该数据所处的位置。若多个数值相同，则等级取它们所在位置的算术平均值。

对数据$X, Y$可定义Spearman相关系数
$$
r_s = 1-\frac{6\sum_i^n d_i^2}{n(n^2-1)}
$$

其中$d_i$是$X_i$和$Y_i$的等级差。可证明，$-1 < r_s < 1$

*另一种定义是，将Spearman相关系数定义为$X$和$Y$等级的Pearson相关系数*

通过Spearman相关系数可判断相关性

小样本（$n \leq 30$）：直接查临界值表
大样本：$r_s \sqrt{n-1} \sim N(0, 1)$


#### 所需假设

待描述的两变量之间线性相关。只有已知两变量线性相关后才能适用Pearson相关系数，系数大则说明相关性强，小则弱。
若不确定两变量是否线性相关，即使Pearson相关系数大也无法说明两者相关。

实验数据通常假设是成对的来自于正态分布的总体

实验数据之间的差距不能太大

每组样本之间是独立抽样的，否则不能进行$t$检验

(连续数据 && 正态分布 && 线性相关) ? Pearson相关系数 : Spearman相关系数;

若无实际数据，只有有序的评级（优良中差），也可适用Spearman相关系数

#### 可能的风险

注意相关系数和检验方法的选择

### 主成分分析

#### 使用场景

对数据进行**降维**描述：将多个指标描述的变量转化为少数几个主成分

#### 实现细节

降维目的：使得数据集更易使用，降低算法的计算开销，去除噪声，使得结果容易理解。

数据有$n$个样本，$p$个指标，可构造$n\times p$大小样本矩阵$x$:

$$
x = \left[
\begin{matrix}
    x_{11} & \cdots & x_{1p} \\
    \vdots & \ddots & \vdots \\
    x_{n1} & \cdots & x_{np}   
\end{matrix} \right] = (\boldsymbol{x}_1, \cdots, \boldsymbol{x}_p)
$$

要找到$m$个主成分$\boldsymbol{z}$，即
$$
\boldsymbol{z} = L_{m\times p}x^T
$$

确定系数$l$：
- $\boldsymbol{z}$的每个成分无关，
- $z_1$是$x$线性组合中方差最大者
- $z_2$与$z_1$不相关，且方差最大
- etc.
- 称$z_1, \cdots, z_i$ 为第1 ... 第m主成分
  
计算：
- 标准化处理
- 计算协方差矩阵$R$
- 计算$R$的特征值和特征向量
- 计算主成分和贡献率
- 写出主成分，分析含义

### 典型相关分析

#### 适用场景

研究由多个指标组成的两组变量之间相关关系的的一种多元统计方法。揭示两组变量的内在联系

#### 实现细节

目的：在每组变量中寻找改组变量的线性组合，来全面综合地反应组的内在规律

两组变量：
$$
X^{(1)} = (X^{(1)}_1, X^{(1)}_2, \cdots, X^{(1)}_p) \\
X^{(2)} = (X^{(2)}_1, X^{(2)}_2, \cdots, X^{(2)}_q)
$$

要分别找到若干综合变量$U_i, V_i$为原变量的线性组合
$$
U_i = \sum_j a_j^{(i)} X_j^{(1)} \\
V_i = \sum_j b_j^{(i)} X_j^{(2)}
$$

每组中，综合变量两两不相关，即协方差为0

第一组$(U_1, V_1)$ 中，在满足 $var(U_1) = var(V_1) = 0$ 的条件下，须找到系数 $\boldsymbol{a}, \boldsymbol{b}$ 使得 $\rho(U_1, V_1)$ 最大

基本精神以上，计算细节建议抄ppt&调包

#### 所需假设

- 两组数据服从联合正态分布
- 两组变量相关


#### 可能的风险

